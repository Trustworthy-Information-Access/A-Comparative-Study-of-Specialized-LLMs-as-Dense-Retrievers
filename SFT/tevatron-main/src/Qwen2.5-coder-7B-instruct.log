/root/paddlejob/workspace/env_run/model/Qwen2.5-coder-7B-instruct
[2025-05-05 21:11:44,028] [INFO] [real_accelerator.py:239:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2025-05-05 21:11:50,792] [WARNING] [runner.py:215:fetch_hostfile] Unable to find hostfile, will proceed with training with local resources only.
[2025-05-05 21:11:50,793] [INFO] [runner.py:605:main] cmd = /usr/bin/python3.10 -u -m deepspeed.launcher.launch --world_info=eyJsb2NhbGhvc3QiOiBbMCwgMSwgMiwgMywgNCwgNSwgNiwgN119 --master_addr=127.0.0.1 --master_port=60001 --module --enable_each_rank_log=None tevatron.retriever.driver.train --deepspeed /root/paddlejob/workspace/env_run/output/tevatron-main/deepspeed/ds_zero3_config.json --output_dir /root/paddlejob/workspace/env_run/output/Qwen2.5-coder-7B-instruct/repllama --model_name_or_path /root/paddlejob/workspace/env_run/model/Qwen2.5-coder-7B-instruct --lora --lora_target_modules q_proj,k_proj,v_proj,o_proj,down_proj,up_proj,gate_proj --save_steps 200 --lora_r 32 --dataset_path /root/paddlejob/workspace/env_run/data/msmarco-pass/repllama-train-tevatron.jsonl --bf16 --pooling eos --append_eos_token --normalize --temperature 0.01 --query_prefix Query: --passage_prefix Passage: --per_device_train_batch_size 4 --gradient_checkpointing --train_group_size 16 --learning_rate 1e-4 --query_max_len 32 --passage_max_len 156 --num_train_epochs 1 --logging_steps 10 --overwrite_output_dir --warmup_steps 100 --gradient_accumulation_steps 4
[2025-05-05 21:11:52,579] [INFO] [real_accelerator.py:239:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2025-05-05 21:11:58,505] [INFO] [launch.py:139:main] 0 NV_LIBNCCL_DEV_PACKAGE=libnccl-dev=2.15.5-1+cuda11.8
[2025-05-05 21:11:58,505] [INFO] [launch.py:139:main] 0 NCCL_IB_GID_INDEX=3
[2025-05-05 21:11:58,505] [INFO] [launch.py:139:main] 0 NCCL_IB_ADAPTIVE_ROUTING=1
[2025-05-05 21:11:58,505] [INFO] [launch.py:139:main] 0 NCCL_IB_DISABLE=0
[2025-05-05 21:11:58,505] [INFO] [launch.py:139:main] 0 SYS_NCCL_CHECK=1
[2025-05-05 21:11:58,505] [INFO] [launch.py:139:main] 0 NCCL_DEBUG_FILE=/root/paddlejob/workspace/log/nccl.%h.%p.log
[2025-05-05 21:11:58,505] [INFO] [launch.py:139:main] 0 NCCL_IB_CONNECT_RETRY_CNT=15
[2025-05-05 21:11:58,505] [INFO] [launch.py:139:main] 0 NCCL_IB_TIMEOUT=22
[2025-05-05 21:11:58,505] [INFO] [launch.py:139:main] 0 NCCL_VERSION=2.15.5-1
[2025-05-05 21:11:58,505] [INFO] [launch.py:139:main] 0 NCCL_IB_CUDA_SUPPORT=0
[2025-05-05 21:11:58,505] [INFO] [launch.py:139:main] 0 NV_LIBNCCL_PACKAGE_VERSION=2.15.5-1
[2025-05-05 21:11:58,505] [INFO] [launch.py:139:main] 0 NV_LIBNCCL_PACKAGE=libnccl2=2.15.5-1+cuda11.8
[2025-05-05 21:11:58,505] [INFO] [launch.py:139:main] 0 NV_LIBNCCL_DEV_PACKAGE_NAME=libnccl-dev
[2025-05-05 21:11:58,505] [INFO] [launch.py:139:main] 0 NV_LIBNCCL_PACKAGE_NAME=libnccl2
[2025-05-05 21:11:58,505] [INFO] [launch.py:139:main] 0 NCCL_P2P_DISABLE=0
[2025-05-05 21:11:58,505] [INFO] [launch.py:139:main] 0 NCCL_IB_QPS_PER_CONNECTION=2
[2025-05-05 21:11:58,505] [INFO] [launch.py:139:main] 0 NCCL_ERROR_FILE=/root/paddlejob/workspace/log/err.%h.%p.log
[2025-05-05 21:11:58,506] [INFO] [launch.py:139:main] 0 NCCL_DEBUG_SUBSYS=INIT,ENV,GRAPH
[2025-05-05 21:11:58,506] [INFO] [launch.py:139:main] 0 NV_LIBNCCL_DEV_PACKAGE_VERSION=2.15.5-1
[2025-05-05 21:11:58,506] [INFO] [launch.py:139:main] 0 NCCL_DEBUG=INFO
[2025-05-05 21:11:58,506] [INFO] [launch.py:139:main] 0 NCCL_SOCKET_IFNAME=xgbe0
[2025-05-05 21:11:58,506] [INFO] [launch.py:146:main] WORLD INFO DICT: {'localhost': [0, 1, 2, 3, 4, 5, 6, 7]}
[2025-05-05 21:11:58,506] [INFO] [launch.py:152:main] nnodes=1, num_local_procs=8, node_rank=0
[2025-05-05 21:11:58,506] [INFO] [launch.py:163:main] global_rank_mapping=defaultdict(<class 'list'>, {'localhost': [0, 1, 2, 3, 4, 5, 6, 7]})
[2025-05-05 21:11:58,506] [INFO] [launch.py:164:main] dist_world_size=8
[2025-05-05 21:11:58,506] [INFO] [launch.py:168:main] Setting CUDA_VISIBLE_DEVICES=0,1,2,3,4,5,6,7
[2025-05-05 21:11:58,507] [INFO] [launch.py:256:main] process 22428 spawned with command: ['/usr/bin/python3.10', '-u', '-m', 'tevatron.retriever.driver.train', '--local_rank=0', '--deepspeed', '/root/paddlejob/workspace/env_run/output/tevatron-main/deepspeed/ds_zero3_config.json', '--output_dir', '/root/paddlejob/workspace/env_run/output/Qwen2.5-coder-7B-instruct/repllama', '--model_name_or_path', '/root/paddlejob/workspace/env_run/model/Qwen2.5-coder-7B-instruct', '--lora', '--lora_target_modules', 'q_proj,k_proj,v_proj,o_proj,down_proj,up_proj,gate_proj', '--save_steps', '200', '--lora_r', '32', '--dataset_path', '/root/paddlejob/workspace/env_run/data/msmarco-pass/repllama-train-tevatron.jsonl', '--bf16', '--pooling', 'eos', '--append_eos_token', '--normalize', '--temperature', '0.01', '--query_prefix', 'Query:', '--passage_prefix', 'Passage:', '--per_device_train_batch_size', '4', '--gradient_checkpointing', '--train_group_size', '16', '--learning_rate', '1e-4', '--query_max_len', '32', '--passage_max_len', '156', '--num_train_epochs', '1', '--logging_steps', '10', '--overwrite_output_dir', '--warmup_steps', '100', '--gradient_accumulation_steps', '4']
[2025-05-05 21:11:58,507] [INFO] [launch.py:256:main] process 22429 spawned with command: ['/usr/bin/python3.10', '-u', '-m', 'tevatron.retriever.driver.train', '--local_rank=1', '--deepspeed', '/root/paddlejob/workspace/env_run/output/tevatron-main/deepspeed/ds_zero3_config.json', '--output_dir', '/root/paddlejob/workspace/env_run/output/Qwen2.5-coder-7B-instruct/repllama', '--model_name_or_path', '/root/paddlejob/workspace/env_run/model/Qwen2.5-coder-7B-instruct', '--lora', '--lora_target_modules', 'q_proj,k_proj,v_proj,o_proj,down_proj,up_proj,gate_proj', '--save_steps', '200', '--lora_r', '32', '--dataset_path', '/root/paddlejob/workspace/env_run/data/msmarco-pass/repllama-train-tevatron.jsonl', '--bf16', '--pooling', 'eos', '--append_eos_token', '--normalize', '--temperature', '0.01', '--query_prefix', 'Query:', '--passage_prefix', 'Passage:', '--per_device_train_batch_size', '4', '--gradient_checkpointing', '--train_group_size', '16', '--learning_rate', '1e-4', '--query_max_len', '32', '--passage_max_len', '156', '--num_train_epochs', '1', '--logging_steps', '10', '--overwrite_output_dir', '--warmup_steps', '100', '--gradient_accumulation_steps', '4']
[2025-05-05 21:11:58,508] [INFO] [launch.py:256:main] process 22430 spawned with command: ['/usr/bin/python3.10', '-u', '-m', 'tevatron.retriever.driver.train', '--local_rank=2', '--deepspeed', '/root/paddlejob/workspace/env_run/output/tevatron-main/deepspeed/ds_zero3_config.json', '--output_dir', '/root/paddlejob/workspace/env_run/output/Qwen2.5-coder-7B-instruct/repllama', '--model_name_or_path', '/root/paddlejob/workspace/env_run/model/Qwen2.5-coder-7B-instruct', '--lora', '--lora_target_modules', 'q_proj,k_proj,v_proj,o_proj,down_proj,up_proj,gate_proj', '--save_steps', '200', '--lora_r', '32', '--dataset_path', '/root/paddlejob/workspace/env_run/data/msmarco-pass/repllama-train-tevatron.jsonl', '--bf16', '--pooling', 'eos', '--append_eos_token', '--normalize', '--temperature', '0.01', '--query_prefix', 'Query:', '--passage_prefix', 'Passage:', '--per_device_train_batch_size', '4', '--gradient_checkpointing', '--train_group_size', '16', '--learning_rate', '1e-4', '--query_max_len', '32', '--passage_max_len', '156', '--num_train_epochs', '1', '--logging_steps', '10', '--overwrite_output_dir', '--warmup_steps', '100', '--gradient_accumulation_steps', '4']
[2025-05-05 21:11:58,509] [INFO] [launch.py:256:main] process 22431 spawned with command: ['/usr/bin/python3.10', '-u', '-m', 'tevatron.retriever.driver.train', '--local_rank=3', '--deepspeed', '/root/paddlejob/workspace/env_run/output/tevatron-main/deepspeed/ds_zero3_config.json', '--output_dir', '/root/paddlejob/workspace/env_run/output/Qwen2.5-coder-7B-instruct/repllama', '--model_name_or_path', '/root/paddlejob/workspace/env_run/model/Qwen2.5-coder-7B-instruct', '--lora', '--lora_target_modules', 'q_proj,k_proj,v_proj,o_proj,down_proj,up_proj,gate_proj', '--save_steps', '200', '--lora_r', '32', '--dataset_path', '/root/paddlejob/workspace/env_run/data/msmarco-pass/repllama-train-tevatron.jsonl', '--bf16', '--pooling', 'eos', '--append_eos_token', '--normalize', '--temperature', '0.01', '--query_prefix', 'Query:', '--passage_prefix', 'Passage:', '--per_device_train_batch_size', '4', '--gradient_checkpointing', '--train_group_size', '16', '--learning_rate', '1e-4', '--query_max_len', '32', '--passage_max_len', '156', '--num_train_epochs', '1', '--logging_steps', '10', '--overwrite_output_dir', '--warmup_steps', '100', '--gradient_accumulation_steps', '4']
[2025-05-05 21:11:58,509] [INFO] [launch.py:256:main] process 22432 spawned with command: ['/usr/bin/python3.10', '-u', '-m', 'tevatron.retriever.driver.train', '--local_rank=4', '--deepspeed', '/root/paddlejob/workspace/env_run/output/tevatron-main/deepspeed/ds_zero3_config.json', '--output_dir', '/root/paddlejob/workspace/env_run/output/Qwen2.5-coder-7B-instruct/repllama', '--model_name_or_path', '/root/paddlejob/workspace/env_run/model/Qwen2.5-coder-7B-instruct', '--lora', '--lora_target_modules', 'q_proj,k_proj,v_proj,o_proj,down_proj,up_proj,gate_proj', '--save_steps', '200', '--lora_r', '32', '--dataset_path', '/root/paddlejob/workspace/env_run/data/msmarco-pass/repllama-train-tevatron.jsonl', '--bf16', '--pooling', 'eos', '--append_eos_token', '--normalize', '--temperature', '0.01', '--query_prefix', 'Query:', '--passage_prefix', 'Passage:', '--per_device_train_batch_size', '4', '--gradient_checkpointing', '--train_group_size', '16', '--learning_rate', '1e-4', '--query_max_len', '32', '--passage_max_len', '156', '--num_train_epochs', '1', '--logging_steps', '10', '--overwrite_output_dir', '--warmup_steps', '100', '--gradient_accumulation_steps', '4']
[2025-05-05 21:11:58,510] [INFO] [launch.py:256:main] process 22433 spawned with command: ['/usr/bin/python3.10', '-u', '-m', 'tevatron.retriever.driver.train', '--local_rank=5', '--deepspeed', '/root/paddlejob/workspace/env_run/output/tevatron-main/deepspeed/ds_zero3_config.json', '--output_dir', '/root/paddlejob/workspace/env_run/output/Qwen2.5-coder-7B-instruct/repllama', '--model_name_or_path', '/root/paddlejob/workspace/env_run/model/Qwen2.5-coder-7B-instruct', '--lora', '--lora_target_modules', 'q_proj,k_proj,v_proj,o_proj,down_proj,up_proj,gate_proj', '--save_steps', '200', '--lora_r', '32', '--dataset_path', '/root/paddlejob/workspace/env_run/data/msmarco-pass/repllama-train-tevatron.jsonl', '--bf16', '--pooling', 'eos', '--append_eos_token', '--normalize', '--temperature', '0.01', '--query_prefix', 'Query:', '--passage_prefix', 'Passage:', '--per_device_train_batch_size', '4', '--gradient_checkpointing', '--train_group_size', '16', '--learning_rate', '1e-4', '--query_max_len', '32', '--passage_max_len', '156', '--num_train_epochs', '1', '--logging_steps', '10', '--overwrite_output_dir', '--warmup_steps', '100', '--gradient_accumulation_steps', '4']
[2025-05-05 21:11:58,511] [INFO] [launch.py:256:main] process 22434 spawned with command: ['/usr/bin/python3.10', '-u', '-m', 'tevatron.retriever.driver.train', '--local_rank=6', '--deepspeed', '/root/paddlejob/workspace/env_run/output/tevatron-main/deepspeed/ds_zero3_config.json', '--output_dir', '/root/paddlejob/workspace/env_run/output/Qwen2.5-coder-7B-instruct/repllama', '--model_name_or_path', '/root/paddlejob/workspace/env_run/model/Qwen2.5-coder-7B-instruct', '--lora', '--lora_target_modules', 'q_proj,k_proj,v_proj,o_proj,down_proj,up_proj,gate_proj', '--save_steps', '200', '--lora_r', '32', '--dataset_path', '/root/paddlejob/workspace/env_run/data/msmarco-pass/repllama-train-tevatron.jsonl', '--bf16', '--pooling', 'eos', '--append_eos_token', '--normalize', '--temperature', '0.01', '--query_prefix', 'Query:', '--passage_prefix', 'Passage:', '--per_device_train_batch_size', '4', '--gradient_checkpointing', '--train_group_size', '16', '--learning_rate', '1e-4', '--query_max_len', '32', '--passage_max_len', '156', '--num_train_epochs', '1', '--logging_steps', '10', '--overwrite_output_dir', '--warmup_steps', '100', '--gradient_accumulation_steps', '4']
[2025-05-05 21:11:58,511] [INFO] [launch.py:256:main] process 22435 spawned with command: ['/usr/bin/python3.10', '-u', '-m', 'tevatron.retriever.driver.train', '--local_rank=7', '--deepspeed', '/root/paddlejob/workspace/env_run/output/tevatron-main/deepspeed/ds_zero3_config.json', '--output_dir', '/root/paddlejob/workspace/env_run/output/Qwen2.5-coder-7B-instruct/repllama', '--model_name_or_path', '/root/paddlejob/workspace/env_run/model/Qwen2.5-coder-7B-instruct', '--lora', '--lora_target_modules', 'q_proj,k_proj,v_proj,o_proj,down_proj,up_proj,gate_proj', '--save_steps', '200', '--lora_r', '32', '--dataset_path', '/root/paddlejob/workspace/env_run/data/msmarco-pass/repllama-train-tevatron.jsonl', '--bf16', '--pooling', 'eos', '--append_eos_token', '--normalize', '--temperature', '0.01', '--query_prefix', 'Query:', '--passage_prefix', 'Passage:', '--per_device_train_batch_size', '4', '--gradient_checkpointing', '--train_group_size', '16', '--learning_rate', '1e-4', '--query_max_len', '32', '--passage_max_len', '156', '--num_train_epochs', '1', '--logging_steps', '10', '--overwrite_output_dir', '--warmup_steps', '100', '--gradient_accumulation_steps', '4']
[2025-05-05 21:12:05,537] [INFO] [real_accelerator.py:239:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2025-05-05 21:12:05,602] [INFO] [real_accelerator.py:239:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2025-05-05 21:12:05,629] [INFO] [real_accelerator.py:239:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2025-05-05 21:12:05,638] [INFO] [real_accelerator.py:239:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2025-05-05 21:12:05,669] [INFO] [real_accelerator.py:239:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2025-05-05 21:12:05,680] [INFO] [real_accelerator.py:239:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2025-05-05 21:12:05,717] [INFO] [real_accelerator.py:239:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2025-05-05 21:12:05,718] [INFO] [real_accelerator.py:239:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2025-05-05 21:12:07,667] [INFO] [comm.py:669:init_distributed] cdb=None
[2025-05-05 21:12:07,667] [INFO] [comm.py:700:init_distributed] Initializing TorchBackend in DeepSpeed with backend nccl
[2025-05-05 21:12:07,801] [INFO] [comm.py:669:init_distributed] cdb=None
[2025-05-05 21:12:07,802] [INFO] [comm.py:669:init_distributed] cdb=None
[2025-05-05 21:12:07,804] [INFO] [comm.py:669:init_distributed] cdb=None
[2025-05-05 21:12:07,873] [INFO] [comm.py:669:init_distributed] cdb=None
[2025-05-05 21:12:07,874] [INFO] [comm.py:669:init_distributed] cdb=None
[2025-05-05 21:12:07,886] [INFO] [comm.py:669:init_distributed] cdb=None
[2025-05-05 21:12:07,923] [INFO] [comm.py:669:init_distributed] cdb=None
[2025-05-05 21:12:08,910] [INFO] [config.py:735:__init__] Config mesh_device None world_size = 8
NCCL version 2.21.5+cuda12.4
[2025-05-05 21:12:09,246] [INFO] [config.py:735:__init__] Config mesh_device None world_size = 8
[2025-05-05 21:12:09,273] [INFO] [config.py:735:__init__] Config mesh_device None world_size = 8
[2025-05-05 21:12:09,274] [INFO] [config.py:735:__init__] Config mesh_device None world_size = 8
[2025-05-05 21:12:09,284] [INFO] [config.py:735:__init__] Config mesh_device None world_size = 8
[2025-05-05 21:12:09,286] [INFO] [config.py:735:__init__] Config mesh_device None world_size = 8
[2025-05-05 21:12:09,298] [INFO] [config.py:735:__init__] Config mesh_device None world_size = 8
[2025-05-05 21:12:09,299] [INFO] [config.py:735:__init__] Config mesh_device None world_size = 8
[2025-05-05 21:12:11,059] [INFO] [partition_parameters.py:348:__exit__] finished initializing model - num_params = 338, num_elems = 7.07B
Parameter Offload: Total persistent parameters: 1250816 in 197 params
[2025-05-05 21:13:06,993] [WARNING] [lr_schedules.py:683:get_lr] Attempting to get learning rate from scheduler before it has started
[2025-05-05 21:13:06,994] [WARNING] [lr_schedules.py:683:get_lr] Attempting to get learning rate from scheduler before it has started
[2025-05-05 21:13:06,994] [WARNING] [lr_schedules.py:683:get_lr] Attempting to get learning rate from scheduler before it has started
[2025-05-05 21:13:06,995] [WARNING] [lr_schedules.py:683:get_lr] Attempting to get learning rate from scheduler before it has started
[2025-05-05 21:13:06,995] [WARNING] [lr_schedules.py:683:get_lr] Attempting to get learning rate from scheduler before it has started
[2025-05-05 21:13:07,008] [WARNING] [lr_schedules.py:683:get_lr] Attempting to get learning rate from scheduler before it has started
[2025-05-05 21:13:07,024] [WARNING] [lr_schedules.py:683:get_lr] Attempting to get learning rate from scheduler before it has started
[2025-05-05 21:13:07,402] [WARNING] [lr_schedules.py:683:get_lr] Attempting to get learning rate from scheduler before it has started
{'loss': 6.0172, 'grad_norm': 7.806462515510177, 'learning_rate': 4.9999999999999996e-05, 'epoch': 0.0}
{'loss': 2.1477, 'grad_norm': 2.935859004318232, 'learning_rate': 6.505149978319905e-05, 'epoch': 0.01}
{'loss': 1.5361, 'grad_norm': 1.5603706718521013, 'learning_rate': 7.385606273598311e-05, 'epoch': 0.01}
{'loss': 1.4211, 'grad_norm': 1.3840582094130445, 'learning_rate': 8.01029995663981e-05, 'epoch': 0.01}
{'loss': 1.3001, 'grad_norm': 1.9106829126027542, 'learning_rate': 8.494850021680092e-05, 'epoch': 0.01}
{'loss': 1.1615, 'grad_norm': 1.9306332829054154, 'learning_rate': 8.890756251918216e-05, 'epoch': 0.02}
{'loss': 1.2057, 'grad_norm': 1.3069539111431798, 'learning_rate': 9.225490200071284e-05, 'epoch': 0.02}
{'loss': 1.158, 'grad_norm': 1.7046226132086542, 'learning_rate': 9.515449934959716e-05, 'epoch': 0.02}
{'loss': 1.0455, 'grad_norm': 1.5330999640681355, 'learning_rate': 9.771212547196623e-05, 'epoch': 0.02}
{'loss': 1.0888, 'grad_norm': 1.307965778157156, 'learning_rate': 9.999999999999999e-05, 'epoch': 0.03}
{'loss': 1.0314, 'grad_norm': 1.4069302911731671, 'learning_rate': 9.97591006423983e-05, 'epoch': 0.03}
{'loss': 1.0617, 'grad_norm': 1.365001436968488, 'learning_rate': 9.94914346895075e-05, 'epoch': 0.03}
{'loss': 1.0531, 'grad_norm': 1.527885875570159, 'learning_rate': 9.92237687366167e-05, 'epoch': 0.03}
{'loss': 1.0845, 'grad_norm': 1.2451339132491572, 'learning_rate': 9.895610278372591e-05, 'epoch': 0.04}
{'loss': 1.0918, 'grad_norm': 1.3547518963579226, 'learning_rate': 9.868843683083512e-05, 'epoch': 0.04}
{'loss': 1.0762, 'grad_norm': 1.2913160036059994, 'learning_rate': 9.842077087794433e-05, 'epoch': 0.04}
{'loss': 1.0306, 'grad_norm': 1.4737774456004453, 'learning_rate': 9.815310492505354e-05, 'epoch': 0.04}
{'loss': 1.0558, 'grad_norm': 1.0794254139168824, 'learning_rate': 9.788543897216274e-05, 'epoch': 0.05}
{'loss': 1.0402, 'grad_norm': 1.502375823336316, 'learning_rate': 9.761777301927195e-05, 'epoch': 0.05}
{'loss': 1.0767, 'grad_norm': 1.2154386341722834, 'learning_rate': 9.735010706638116e-05, 'epoch': 0.05}
{'loss': 1.0187, 'grad_norm': 1.4660519048268397, 'learning_rate': 9.708244111349037e-05, 'epoch': 0.05}
{'loss': 0.9613, 'grad_norm': 1.4216770296892707, 'learning_rate': 9.681477516059958e-05, 'epoch': 0.06}
{'loss': 1.0486, 'grad_norm': 1.4802187025782403, 'learning_rate': 9.654710920770879e-05, 'epoch': 0.06}
{'loss': 1.0213, 'grad_norm': 1.2967713916747874, 'learning_rate': 9.627944325481799e-05, 'epoch': 0.06}
{'loss': 0.9695, 'grad_norm': 1.3095893014289515, 'learning_rate': 9.60117773019272e-05, 'epoch': 0.07}
{'loss': 1.0279, 'grad_norm': 1.0285463650956388, 'learning_rate': 9.57441113490364e-05, 'epoch': 0.07}
{'loss': 1.0269, 'grad_norm': 1.3581357665279457, 'learning_rate': 9.547644539614562e-05, 'epoch': 0.07}
{'loss': 0.9842, 'grad_norm': 1.2405438306353864, 'learning_rate': 9.520877944325483e-05, 'epoch': 0.07}
{'loss': 0.9778, 'grad_norm': 1.2388521792256502, 'learning_rate': 9.494111349036404e-05, 'epoch': 0.08}
{'loss': 0.9867, 'grad_norm': 1.428241832182578, 'learning_rate': 9.467344753747323e-05, 'epoch': 0.08}
{'loss': 1.0298, 'grad_norm': 1.1114472328973537, 'learning_rate': 9.440578158458244e-05, 'epoch': 0.08}
{'loss': 0.9724, 'grad_norm': 1.3760651938852038, 'learning_rate': 9.413811563169165e-05, 'epoch': 0.08}
{'loss': 0.9892, 'grad_norm': 1.2365336339154507, 'learning_rate': 9.387044967880086e-05, 'epoch': 0.09}
{'loss': 0.9662, 'grad_norm': 1.1425046987110454, 'learning_rate': 9.360278372591007e-05, 'epoch': 0.09}
{'loss': 0.9891, 'grad_norm': 1.0848100938074434, 'learning_rate': 9.333511777301927e-05, 'epoch': 0.09}
{'loss': 1.0075, 'grad_norm': 1.2861892183027426, 'learning_rate': 9.306745182012848e-05, 'epoch': 0.09}
{'loss': 0.9798, 'grad_norm': 1.0246929896628836, 'learning_rate': 9.279978586723769e-05, 'epoch': 0.1}
{'loss': 0.9535, 'grad_norm': 1.232335241761253, 'learning_rate': 9.25321199143469e-05, 'epoch': 0.1}
{'loss': 0.9339, 'grad_norm': 1.2054126492416763, 'learning_rate': 9.226445396145611e-05, 'epoch': 0.1}
{'loss': 0.9701, 'grad_norm': 1.132638676963208, 'learning_rate': 9.199678800856532e-05, 'epoch': 0.1}
{'loss': 1.0052, 'grad_norm': 1.1723372270153116, 'learning_rate': 9.172912205567452e-05, 'epoch': 0.11}
{'loss': 0.9835, 'grad_norm': 1.348145712522745, 'learning_rate': 9.146145610278373e-05, 'epoch': 0.11}
{'loss': 0.9504, 'grad_norm': 1.041827455880693, 'learning_rate': 9.119379014989294e-05, 'epoch': 0.11}
{'loss': 0.9621, 'grad_norm': 1.0442155447017225, 'learning_rate': 9.092612419700215e-05, 'epoch': 0.11}
{'loss': 0.9669, 'grad_norm': 1.447559161048807, 'learning_rate': 9.065845824411136e-05, 'epoch': 0.12}
{'loss': 0.9643, 'grad_norm': 1.0847636900644402, 'learning_rate': 9.039079229122057e-05, 'epoch': 0.12}
{'loss': 0.9577, 'grad_norm': 1.0878608820625182, 'learning_rate': 9.012312633832976e-05, 'epoch': 0.12}
{'loss': 0.9599, 'grad_norm': 1.380287203184142, 'learning_rate': 8.985546038543897e-05, 'epoch': 0.13}
{'loss': 0.9325, 'grad_norm': 1.2454733684856525, 'learning_rate': 8.958779443254818e-05, 'epoch': 0.13}
{'loss': 0.9528, 'grad_norm': 1.1500454413691423, 'learning_rate': 8.932012847965739e-05, 'epoch': 0.13}
{'loss': 0.9457, 'grad_norm': 1.0932637479589866, 'learning_rate': 8.90524625267666e-05, 'epoch': 0.13}
{'loss': 0.9855, 'grad_norm': 0.9972349108013536, 'learning_rate': 8.87847965738758e-05, 'epoch': 0.14}
{'loss': 0.9542, 'grad_norm': 1.1437926777668255, 'learning_rate': 8.851713062098501e-05, 'epoch': 0.14}
{'loss': 1.0265, 'grad_norm': 1.1505230658739873, 'learning_rate': 8.824946466809422e-05, 'epoch': 0.14}
{'loss': 0.9438, 'grad_norm': 1.125293445017882, 'learning_rate': 8.798179871520343e-05, 'epoch': 0.14}
{'loss': 0.9346, 'grad_norm': 1.0110716229857926, 'learning_rate': 8.771413276231264e-05, 'epoch': 0.15}
{'loss': 0.9411, 'grad_norm': 1.3073047745410808, 'learning_rate': 8.744646680942185e-05, 'epoch': 0.15}
{'loss': 0.9675, 'grad_norm': 1.2680684239931435, 'learning_rate': 8.717880085653105e-05, 'epoch': 0.15}
{'loss': 0.9388, 'grad_norm': 1.333701459107693, 'learning_rate': 8.691113490364026e-05, 'epoch': 0.15}
{'loss': 0.9468, 'grad_norm': 1.1045431010864217, 'learning_rate': 8.664346895074948e-05, 'epoch': 0.16}
{'loss': 0.9051, 'grad_norm': 1.1661456874047464, 'learning_rate': 8.637580299785868e-05, 'epoch': 0.16}
{'loss': 0.9306, 'grad_norm': 1.0226254916728656, 'learning_rate': 8.610813704496789e-05, 'epoch': 0.16}
{'loss': 0.9531, 'grad_norm': 1.1629821496323829, 'learning_rate': 8.58404710920771e-05, 'epoch': 0.16}
{'loss': 0.9508, 'grad_norm': 1.1995267227464914, 'learning_rate': 8.557280513918629e-05, 'epoch': 0.17}
{'loss': 0.8877, 'grad_norm': 1.149000585841751, 'learning_rate': 8.53051391862955e-05, 'epoch': 0.17}
{'loss': 0.9383, 'grad_norm': 1.0705935075354225, 'learning_rate': 8.503747323340471e-05, 'epoch': 0.17}
{'loss': 0.897, 'grad_norm': 1.2438025837953153, 'learning_rate': 8.476980728051392e-05, 'epoch': 0.17}
{'loss': 1.0225, 'grad_norm': 1.1604139529768425, 'learning_rate': 8.450214132762313e-05, 'epoch': 0.18}
{'loss': 0.9751, 'grad_norm': 0.9406464217136261, 'learning_rate': 8.423447537473233e-05, 'epoch': 0.18}
{'loss': 0.9066, 'grad_norm': 1.1693993890735563, 'learning_rate': 8.396680942184154e-05, 'epoch': 0.18}
{'loss': 0.9163, 'grad_norm': 1.267301515127197, 'learning_rate': 8.369914346895076e-05, 'epoch': 0.19}
{'loss': 0.9163, 'grad_norm': 0.904943751274796, 'learning_rate': 8.343147751605996e-05, 'epoch': 0.19}
{'loss': 0.984, 'grad_norm': 1.0758483659204896, 'learning_rate': 8.316381156316917e-05, 'epoch': 0.19}
{'loss': 0.9552, 'grad_norm': 0.9385556290691774, 'learning_rate': 8.289614561027838e-05, 'epoch': 0.19}
{'loss': 0.9044, 'grad_norm': 1.1777532215451882, 'learning_rate': 8.262847965738758e-05, 'epoch': 0.2}
{'loss': 0.9818, 'grad_norm': 1.114286460676385, 'learning_rate': 8.236081370449679e-05, 'epoch': 0.2}
{'loss': 0.9701, 'grad_norm': 1.1238096089089393, 'learning_rate': 8.209314775160601e-05, 'epoch': 0.2}
{'loss': 0.8982, 'grad_norm': 0.9833726765246755, 'learning_rate': 8.18254817987152e-05, 'epoch': 0.2}
{'loss': 0.9322, 'grad_norm': 1.2381417870885587, 'learning_rate': 8.155781584582442e-05, 'epoch': 0.21}
{'loss': 0.9197, 'grad_norm': 1.1930451513337805, 'learning_rate': 8.129014989293363e-05, 'epoch': 0.21}
{'loss': 0.8769, 'grad_norm': 1.049712613180827, 'learning_rate': 8.102248394004282e-05, 'epoch': 0.21}
{'loss': 0.8224, 'grad_norm': 1.135192106465622, 'learning_rate': 8.075481798715205e-05, 'epoch': 0.21}
{'loss': 0.9165, 'grad_norm': 1.151304479189897, 'learning_rate': 8.048715203426124e-05, 'epoch': 0.22}
{'loss': 0.8898, 'grad_norm': 1.0116569702211478, 'learning_rate': 8.021948608137045e-05, 'epoch': 0.22}
{'loss': 0.8884, 'grad_norm': 1.0050941490164236, 'learning_rate': 7.995182012847966e-05, 'epoch': 0.22}
{'loss': 0.9166, 'grad_norm': 1.0177099966096068, 'learning_rate': 7.968415417558886e-05, 'epoch': 0.22}
{'loss': 0.8807, 'grad_norm': 1.078511092065381, 'learning_rate': 7.941648822269807e-05, 'epoch': 0.23}
{'loss': 0.8917, 'grad_norm': 1.0522788054685086, 'learning_rate': 7.914882226980729e-05, 'epoch': 0.23}
{'loss': 0.9413, 'grad_norm': 1.220234498770887, 'learning_rate': 7.888115631691649e-05, 'epoch': 0.23}
{'loss': 0.92, 'grad_norm': 1.0770416460443961, 'learning_rate': 7.86134903640257e-05, 'epoch': 0.23}
{'loss': 0.8971, 'grad_norm': 1.114515049353562, 'learning_rate': 7.834582441113491e-05, 'epoch': 0.24}
{'loss': 0.8864, 'grad_norm': 1.1649366479927383, 'learning_rate': 7.80781584582441e-05, 'epoch': 0.24}
{'loss': 0.9265, 'grad_norm': 1.145385586753562, 'learning_rate': 7.781049250535333e-05, 'epoch': 0.24}
{'loss': 0.8832, 'grad_norm': 1.1977760996285636, 'learning_rate': 7.754282655246254e-05, 'epoch': 0.25}
{'loss': 0.9435, 'grad_norm': 0.9719712132592313, 'learning_rate': 7.727516059957174e-05, 'epoch': 0.25}
{'loss': 0.9648, 'grad_norm': 1.0003055450588052, 'learning_rate': 7.700749464668095e-05, 'epoch': 0.25}
{'loss': 0.9012, 'grad_norm': 1.154592095936426, 'learning_rate': 7.673982869379016e-05, 'epoch': 0.25}
{'loss': 0.8928, 'grad_norm': 1.054704200913825, 'learning_rate': 7.647216274089935e-05, 'epoch': 0.26}
{'loss': 0.9468, 'grad_norm': 1.0554245482876152, 'learning_rate': 7.620449678800858e-05, 'epoch': 0.26}
{'loss': 0.8961, 'grad_norm': 1.0838397708249754, 'learning_rate': 7.593683083511777e-05, 'epoch': 0.26}
{'loss': 0.9563, 'grad_norm': 1.1543471258585483, 'learning_rate': 7.566916488222698e-05, 'epoch': 0.26}
{'loss': 0.9418, 'grad_norm': 0.9544303342149077, 'learning_rate': 7.540149892933619e-05, 'epoch': 0.27}
{'loss': 0.9048, 'grad_norm': 1.1636282333175396, 'learning_rate': 7.51338329764454e-05, 'epoch': 0.27}
{'loss': 0.8462, 'grad_norm': 0.9850978450466413, 'learning_rate': 7.486616702355461e-05, 'epoch': 0.27}
{'loss': 0.9232, 'grad_norm': 1.034697614489331, 'learning_rate': 7.459850107066382e-05, 'epoch': 0.27}
{'loss': 0.9342, 'grad_norm': 0.9772370285689415, 'learning_rate': 7.433083511777302e-05, 'epoch': 0.28}
{'loss': 0.919, 'grad_norm': 1.1098991966454987, 'learning_rate': 7.406316916488223e-05, 'epoch': 0.28}
{'loss': 0.9192, 'grad_norm': 1.134889717201417, 'learning_rate': 7.379550321199144e-05, 'epoch': 0.28}
{'loss': 0.9066, 'grad_norm': 1.1886980412665218, 'learning_rate': 7.352783725910065e-05, 'epoch': 0.28}
{'loss': 0.8909, 'grad_norm': 1.0028353334658622, 'learning_rate': 7.326017130620986e-05, 'epoch': 0.29}
{'loss': 0.8774, 'grad_norm': 1.0636887506243446, 'learning_rate': 7.299250535331907e-05, 'epoch': 0.29}
{'loss': 0.9519, 'grad_norm': 0.9974443107043521, 'learning_rate': 7.272483940042827e-05, 'epoch': 0.29}
{'loss': 0.9156, 'grad_norm': 0.9754116182053317, 'learning_rate': 7.245717344753748e-05, 'epoch': 0.29}
{'loss': 0.9097, 'grad_norm': 1.036138433850001, 'learning_rate': 7.218950749464669e-05, 'epoch': 0.3}
{'loss': 0.9115, 'grad_norm': 1.0419746816103148, 'learning_rate': 7.19218415417559e-05, 'epoch': 0.3}
{'loss': 0.9762, 'grad_norm': 1.0539791019891742, 'learning_rate': 7.16541755888651e-05, 'epoch': 0.3}
{'loss': 0.9316, 'grad_norm': 1.0305938085812139, 'learning_rate': 7.13865096359743e-05, 'epoch': 0.31}
{'loss': 0.9077, 'grad_norm': 0.9752808657554016, 'learning_rate': 7.111884368308351e-05, 'epoch': 0.31}
{'loss': 0.9143, 'grad_norm': 0.9138129074313469, 'learning_rate': 7.085117773019272e-05, 'epoch': 0.31}
{'loss': 0.9158, 'grad_norm': 0.9763510045740067, 'learning_rate': 7.058351177730193e-05, 'epoch': 0.31}
{'loss': 0.9387, 'grad_norm': 1.1300754095726742, 'learning_rate': 7.031584582441114e-05, 'epoch': 0.32}
{'loss': 0.8794, 'grad_norm': 1.0663302017565373, 'learning_rate': 7.004817987152035e-05, 'epoch': 0.32}
{'loss': 0.9399, 'grad_norm': 1.2262061899687717, 'learning_rate': 6.978051391862955e-05, 'epoch': 0.32}
{'loss': 0.8978, 'grad_norm': 1.158626574391291, 'learning_rate': 6.951284796573876e-05, 'epoch': 0.32}
{'loss': 0.8596, 'grad_norm': 0.9711000306515879, 'learning_rate': 6.924518201284797e-05, 'epoch': 0.33}
{'loss': 0.9083, 'grad_norm': 1.0308401731427603, 'learning_rate': 6.897751605995718e-05, 'epoch': 0.33}
{'loss': 0.8996, 'grad_norm': 1.0167113003033552, 'learning_rate': 6.870985010706639e-05, 'epoch': 0.33}
{'loss': 0.9449, 'grad_norm': 1.266461368702829, 'learning_rate': 6.84421841541756e-05, 'epoch': 0.33}
{'loss': 0.9216, 'grad_norm': 0.9735569968976927, 'learning_rate': 6.81745182012848e-05, 'epoch': 0.34}
{'loss': 0.9169, 'grad_norm': 1.0820212386163444, 'learning_rate': 6.7906852248394e-05, 'epoch': 0.34}
{'loss': 0.9029, 'grad_norm': 1.0988441441104702, 'learning_rate': 6.763918629550321e-05, 'epoch': 0.34}
{'loss': 0.9621, 'grad_norm': 1.0844019829435436, 'learning_rate': 6.737152034261242e-05, 'epoch': 0.34}
{'loss': 0.9239, 'grad_norm': 0.9354728261222045, 'learning_rate': 6.710385438972163e-05, 'epoch': 0.35}
{'loss': 0.8798, 'grad_norm': 1.0933683679137718, 'learning_rate': 6.683618843683083e-05, 'epoch': 0.35}
{'loss': 0.9256, 'grad_norm': 1.0378757749250966, 'learning_rate': 6.656852248394004e-05, 'epoch': 0.35}
{'loss': 0.9164, 'grad_norm': 1.1302046745951413, 'learning_rate': 6.630085653104925e-05, 'epoch': 0.35}
{'loss': 0.8444, 'grad_norm': 0.9336500878422485, 'learning_rate': 6.603319057815846e-05, 'epoch': 0.36}
{'loss': 0.9447, 'grad_norm': 1.017636645162207, 'learning_rate': 6.576552462526767e-05, 'epoch': 0.36}
{'loss': 0.8808, 'grad_norm': 1.0455261040404573, 'learning_rate': 6.549785867237688e-05, 'epoch': 0.36}
{'loss': 0.9211, 'grad_norm': 1.1729518780203765, 'learning_rate': 6.523019271948608e-05, 'epoch': 0.36}
{'loss': 0.8938, 'grad_norm': 1.1610568206100969, 'learning_rate': 6.496252676659529e-05, 'epoch': 0.37}
{'loss': 0.857, 'grad_norm': 1.1763290789195384, 'learning_rate': 6.469486081370451e-05, 'epoch': 0.37}
{'loss': 0.9352, 'grad_norm': 0.8479435720992666, 'learning_rate': 6.442719486081371e-05, 'epoch': 0.37}
{'loss': 0.9271, 'grad_norm': 1.1184659873830585, 'learning_rate': 6.415952890792292e-05, 'epoch': 0.38}
{'loss': 0.8943, 'grad_norm': 1.5451243835878004, 'learning_rate': 6.389186295503213e-05, 'epoch': 0.38}
{'loss': 0.857, 'grad_norm': 1.235292558097763, 'learning_rate': 6.362419700214132e-05, 'epoch': 0.38}
{'loss': 0.8799, 'grad_norm': 1.0044160651153042, 'learning_rate': 6.335653104925053e-05, 'epoch': 0.38}
{'loss': 0.9134, 'grad_norm': 1.0665607896658387, 'learning_rate': 6.308886509635974e-05, 'epoch': 0.39}
{'loss': 0.923, 'grad_norm': 0.8688743710970923, 'learning_rate': 6.282119914346895e-05, 'epoch': 0.39}
{'loss': 0.8795, 'grad_norm': 1.1777595346005612, 'learning_rate': 6.255353319057816e-05, 'epoch': 0.39}
{'loss': 0.8689, 'grad_norm': 0.9540511306138199, 'learning_rate': 6.228586723768736e-05, 'epoch': 0.39}
{'loss': 0.9399, 'grad_norm': 0.9721145549432532, 'learning_rate': 6.201820128479657e-05, 'epoch': 0.4}
{'loss': 0.9289, 'grad_norm': 0.9604766462818503, 'learning_rate': 6.17505353319058e-05, 'epoch': 0.4}
{'loss': 0.9229, 'grad_norm': 0.9667235810671607, 'learning_rate': 6.148286937901499e-05, 'epoch': 0.4}
{'loss': 0.8814, 'grad_norm': 0.9825164073646708, 'learning_rate': 6.12152034261242e-05, 'epoch': 0.4}
{'loss': 0.8421, 'grad_norm': 1.0709089303705552, 'learning_rate': 6.0947537473233405e-05, 'epoch': 0.41}
{'loss': 0.9204, 'grad_norm': 0.9440751211112725, 'learning_rate': 6.0679871520342615e-05, 'epoch': 0.41}
{'loss': 0.8613, 'grad_norm': 1.289213629398871, 'learning_rate': 6.041220556745182e-05, 'epoch': 0.41}
{'loss': 0.8943, 'grad_norm': 0.8742452193828624, 'learning_rate': 6.0144539614561035e-05, 'epoch': 0.41}
{'loss': 0.8798, 'grad_norm': 1.0991938265446233, 'learning_rate': 5.987687366167024e-05, 'epoch': 0.42}
{'loss': 0.9043, 'grad_norm': 1.0428079948435804, 'learning_rate': 5.960920770877945e-05, 'epoch': 0.42}
{'loss': 0.8223, 'grad_norm': 1.0620260507546286, 'learning_rate': 5.934154175588865e-05, 'epoch': 0.42}
{'loss': 0.8944, 'grad_norm': 0.98583976530869, 'learning_rate': 5.907387580299786e-05, 'epoch': 0.42}
{'loss': 0.8844, 'grad_norm': 0.977604460958065, 'learning_rate': 5.880620985010708e-05, 'epoch': 0.43}
{'loss': 0.8615, 'grad_norm': 1.0653080369654058, 'learning_rate': 5.853854389721628e-05, 'epoch': 0.43}
{'loss': 0.9003, 'grad_norm': 0.9669310009804376, 'learning_rate': 5.8270877944325484e-05, 'epoch': 0.43}
{'loss': 0.8318, 'grad_norm': 1.007710485352933, 'learning_rate': 5.8003211991434694e-05, 'epoch': 0.44}
{'loss': 0.8369, 'grad_norm': 1.0471611946939439, 'learning_rate': 5.77355460385439e-05, 'epoch': 0.44}
{'loss': 0.9477, 'grad_norm': 1.027194063838612, 'learning_rate': 5.74678800856531e-05, 'epoch': 0.44}
{'loss': 0.8513, 'grad_norm': 1.1459674701088023, 'learning_rate': 5.720021413276232e-05, 'epoch': 0.44}
{'loss': 0.8818, 'grad_norm': 1.0233871475489271, 'learning_rate': 5.693254817987153e-05, 'epoch': 0.45}
{'loss': 0.898, 'grad_norm': 1.009869404867333, 'learning_rate': 5.666488222698073e-05, 'epoch': 0.45}
{'loss': 0.9383, 'grad_norm': 1.0139362697281002, 'learning_rate': 5.6397216274089934e-05, 'epoch': 0.45}
{'loss': 0.8889, 'grad_norm': 1.0133613452883263, 'learning_rate': 5.6129550321199144e-05, 'epoch': 0.45}
{'loss': 0.8654, 'grad_norm': 1.1853984515228315, 'learning_rate': 5.586188436830836e-05, 'epoch': 0.46}
{'loss': 0.8481, 'grad_norm': 1.0088185106091236, 'learning_rate': 5.5594218415417564e-05, 'epoch': 0.46}
{'loss': 0.9245, 'grad_norm': 1.2277264807341604, 'learning_rate': 5.532655246252677e-05, 'epoch': 0.46}
{'loss': 0.8919, 'grad_norm': 0.9578218483873777, 'learning_rate': 5.505888650963598e-05, 'epoch': 0.46}
{'loss': 0.8633, 'grad_norm': 1.0583901651673508, 'learning_rate': 5.479122055674518e-05, 'epoch': 0.47}
{'loss': 0.8898, 'grad_norm': 1.004221946848212, 'learning_rate': 5.452355460385439e-05, 'epoch': 0.47}
{'loss': 0.8332, 'grad_norm': 0.8052116583884289, 'learning_rate': 5.425588865096361e-05, 'epoch': 0.47}
{'loss': 0.9312, 'grad_norm': 0.9341100318096726, 'learning_rate': 5.398822269807281e-05, 'epoch': 0.47}
{'loss': 0.8815, 'grad_norm': 1.0380578588839589, 'learning_rate': 5.3720556745182014e-05, 'epoch': 0.48}
{'loss': 0.9176, 'grad_norm': 1.0000473603848936, 'learning_rate': 5.3452890792291224e-05, 'epoch': 0.48}
{'loss': 0.9243, 'grad_norm': 0.9539960250689797, 'learning_rate': 5.318522483940043e-05, 'epoch': 0.48}
{'loss': 0.8647, 'grad_norm': 0.9029095144534633, 'learning_rate': 5.2917558886509644e-05, 'epoch': 0.48}
{'loss': 0.8733, 'grad_norm': 1.0509871009668152, 'learning_rate': 5.264989293361885e-05, 'epoch': 0.49}
{'loss': 0.8726, 'grad_norm': 1.1880636102391668, 'learning_rate': 5.238222698072806e-05, 'epoch': 0.49}
{'loss': 0.8993, 'grad_norm': 1.0258509220535525, 'learning_rate': 5.211456102783726e-05, 'epoch': 0.49}
{'loss': 0.838, 'grad_norm': 1.029715341659591, 'learning_rate': 5.1846895074946464e-05, 'epoch': 0.5}
{'loss': 0.8772, 'grad_norm': 1.1037546036282095, 'learning_rate': 5.1579229122055674e-05, 'epoch': 0.5}
{'loss': 0.8366, 'grad_norm': 0.9966408912440019, 'learning_rate': 5.131156316916489e-05, 'epoch': 0.5}
{'loss': 0.8576, 'grad_norm': 0.931414204842836, 'learning_rate': 5.1043897216274094e-05, 'epoch': 0.5}
{'loss': 0.8555, 'grad_norm': 0.9435252875390623, 'learning_rate': 5.07762312633833e-05, 'epoch': 0.51}
{'loss': 0.9266, 'grad_norm': 1.2361359606150768, 'learning_rate': 5.050856531049251e-05, 'epoch': 0.51}
{'loss': 0.8407, 'grad_norm': 1.0630816839382693, 'learning_rate': 5.024089935760171e-05, 'epoch': 0.51}
{'loss': 0.8729, 'grad_norm': 1.1374081162068077, 'learning_rate': 4.997323340471092e-05, 'epoch': 0.51}
{'loss': 0.8487, 'grad_norm': 1.0040502780597698, 'learning_rate': 4.970556745182013e-05, 'epoch': 0.52}
{'loss': 0.8763, 'grad_norm': 1.0920879584234469, 'learning_rate': 4.943790149892934e-05, 'epoch': 0.52}
{'loss': 0.8975, 'grad_norm': 0.9519320645244048, 'learning_rate': 4.9170235546038544e-05, 'epoch': 0.52}
{'loss': 0.8517, 'grad_norm': 1.035878741159019, 'learning_rate': 4.8902569593147754e-05, 'epoch': 0.52}
{'loss': 0.9092, 'grad_norm': 1.0971859663810677, 'learning_rate': 4.8634903640256964e-05, 'epoch': 0.53}
{'loss': 0.8296, 'grad_norm': 0.8997532513590039, 'learning_rate': 4.836723768736617e-05, 'epoch': 0.53}
{'loss': 0.8994, 'grad_norm': 1.120944217336009, 'learning_rate': 4.809957173447538e-05, 'epoch': 0.53}
{'loss': 0.8706, 'grad_norm': 1.100214226156985, 'learning_rate': 4.783190578158459e-05, 'epoch': 0.53}
{'loss': 0.8953, 'grad_norm': 1.0140359841780402, 'learning_rate': 4.756423982869379e-05, 'epoch': 0.54}
{'loss': 0.8588, 'grad_norm': 0.9391511626226827, 'learning_rate': 4.7296573875803e-05, 'epoch': 0.54}
{'loss': 0.8708, 'grad_norm': 1.1023944047443024, 'learning_rate': 4.702890792291221e-05, 'epoch': 0.54}
{'loss': 0.8283, 'grad_norm': 1.1359236890516147, 'learning_rate': 4.6761241970021414e-05, 'epoch': 0.54}
{'loss': 0.8751, 'grad_norm': 1.217593587285242, 'learning_rate': 4.6493576017130624e-05, 'epoch': 0.55}
{'loss': 0.8358, 'grad_norm': 1.010143590645457, 'learning_rate': 4.622591006423983e-05, 'epoch': 0.55}
{'loss': 0.8294, 'grad_norm': 1.0326492984117093, 'learning_rate': 4.595824411134904e-05, 'epoch': 0.55}
{'loss': 0.8325, 'grad_norm': 0.9094334886375733, 'learning_rate': 4.569057815845825e-05, 'epoch': 0.56}
{'loss': 0.9216, 'grad_norm': 1.159442462622674, 'learning_rate': 4.542291220556745e-05, 'epoch': 0.56}
{'loss': 0.8838, 'grad_norm': 1.0558854622027516, 'learning_rate': 4.515524625267667e-05, 'epoch': 0.56}
{'loss': 0.8718, 'grad_norm': 0.906679632312663, 'learning_rate': 4.488758029978587e-05, 'epoch': 0.56}
{'loss': 0.8444, 'grad_norm': 0.9732368726388484, 'learning_rate': 4.4619914346895074e-05, 'epoch': 0.57}
{'loss': 0.8983, 'grad_norm': 1.1220026348470384, 'learning_rate': 4.4352248394004284e-05, 'epoch': 0.57}
{'loss': 0.8731, 'grad_norm': 1.0352882340955833, 'learning_rate': 4.4084582441113494e-05, 'epoch': 0.57}
{'loss': 0.7888, 'grad_norm': 0.9849853955994025, 'learning_rate': 4.38169164882227e-05, 'epoch': 0.57}
{'loss': 0.8669, 'grad_norm': 1.156320698839723, 'learning_rate': 4.354925053533191e-05, 'epoch': 0.58}
{'loss': 0.8783, 'grad_norm': 0.8493235381844868, 'learning_rate': 4.328158458244112e-05, 'epoch': 0.58}
{'loss': 0.8924, 'grad_norm': 0.9441815473856198, 'learning_rate': 4.301391862955033e-05, 'epoch': 0.58}
{'loss': 0.8661, 'grad_norm': 1.0544145673004426, 'learning_rate': 4.274625267665953e-05, 'epoch': 0.58}
{'loss': 0.8932, 'grad_norm': 1.1256190788566933, 'learning_rate': 4.247858672376874e-05, 'epoch': 0.59}
{'loss': 0.8616, 'grad_norm': 1.2131227668714775, 'learning_rate': 4.221092077087795e-05, 'epoch': 0.59}
{'loss': 0.8884, 'grad_norm': 1.0354832652561368, 'learning_rate': 4.1943254817987154e-05, 'epoch': 0.59}
{'loss': 0.8944, 'grad_norm': 1.000526494419168, 'learning_rate': 4.167558886509636e-05, 'epoch': 0.59}
{'loss': 0.8962, 'grad_norm': 1.0373257179034119, 'learning_rate': 4.1407922912205574e-05, 'epoch': 0.6}
{'loss': 0.8985, 'grad_norm': 1.045143123012078, 'learning_rate': 4.114025695931478e-05, 'epoch': 0.6}
{'loss': 0.8299, 'grad_norm': 0.9010889083068173, 'learning_rate': 4.087259100642398e-05, 'epoch': 0.6}
{'loss': 0.8859, 'grad_norm': 0.9941003953440126, 'learning_rate': 4.06049250535332e-05, 'epoch': 0.6}
{'loss': 0.8536, 'grad_norm': 1.0414045079045235, 'learning_rate': 4.03372591006424e-05, 'epoch': 0.61}
{'loss': 0.8696, 'grad_norm': 0.9732909708679299, 'learning_rate': 4.006959314775161e-05, 'epoch': 0.61}
{'loss': 0.9216, 'grad_norm': 1.1094551416029397, 'learning_rate': 3.9801927194860814e-05, 'epoch': 0.61}
{'loss': 0.8063, 'grad_norm': 0.9693565022854774, 'learning_rate': 3.9534261241970024e-05, 'epoch': 0.62}
{'loss': 0.8801, 'grad_norm': 0.9112770786852685, 'learning_rate': 3.9266595289079234e-05, 'epoch': 0.62}
{'loss': 0.8953, 'grad_norm': 1.2269182074910339, 'learning_rate': 3.899892933618844e-05, 'epoch': 0.62}
{'loss': 0.8961, 'grad_norm': 1.0777285305122646, 'learning_rate': 3.873126338329765e-05, 'epoch': 0.62}
{'loss': 0.8611, 'grad_norm': 0.959344255126838, 'learning_rate': 3.846359743040686e-05, 'epoch': 0.63}
{'loss': 0.8373, 'grad_norm': 0.9812331838129951, 'learning_rate': 3.819593147751606e-05, 'epoch': 0.63}
{'loss': 0.8921, 'grad_norm': 1.1379084966701098, 'learning_rate': 3.792826552462527e-05, 'epoch': 0.63}
{'loss': 0.8625, 'grad_norm': 0.9709096355352069, 'learning_rate': 3.766059957173448e-05, 'epoch': 0.63}
{'loss': 0.8319, 'grad_norm': 1.0753463253800948, 'learning_rate': 3.7392933618843683e-05, 'epoch': 0.64}
{'loss': 0.9068, 'grad_norm': 1.1679201694380856, 'learning_rate': 3.7125267665952893e-05, 'epoch': 0.64}
{'loss': 0.8993, 'grad_norm': 0.9549750190672666, 'learning_rate': 3.6857601713062103e-05, 'epoch': 0.64}
{'loss': 0.8392, 'grad_norm': 1.0879529444084084, 'learning_rate': 3.658993576017131e-05, 'epoch': 0.64}
{'loss': 0.8727, 'grad_norm': 1.0600844228529671, 'learning_rate': 3.632226980728052e-05, 'epoch': 0.65}
{'loss': 0.89, 'grad_norm': 1.062975251224852, 'learning_rate': 3.605460385438973e-05, 'epoch': 0.65}
{'loss': 0.9152, 'grad_norm': 1.1535570818422045, 'learning_rate': 3.578693790149893e-05, 'epoch': 0.65}
{'loss': 0.8705, 'grad_norm': 1.0497441864811476, 'learning_rate': 3.551927194860814e-05, 'epoch': 0.65}
{'loss': 0.8301, 'grad_norm': 0.9420552616387884, 'learning_rate': 3.525160599571734e-05, 'epoch': 0.66}
{'loss': 0.8491, 'grad_norm': 1.0675910866550238, 'learning_rate': 3.498394004282655e-05, 'epoch': 0.66}
{'loss': 0.8927, 'grad_norm': 1.2243155421358434, 'learning_rate': 3.471627408993576e-05, 'epoch': 0.66}
{'loss': 0.8703, 'grad_norm': 0.9620596581389512, 'learning_rate': 3.4448608137044967e-05, 'epoch': 0.66}
{'loss': 0.8667, 'grad_norm': 1.0619130960295557, 'learning_rate': 3.418094218415418e-05, 'epoch': 0.67}
{'loss': 0.8767, 'grad_norm': 1.0153461202750331, 'learning_rate': 3.391327623126339e-05, 'epoch': 0.67}
{'loss': 0.8312, 'grad_norm': 1.0936470167727455, 'learning_rate': 3.364561027837259e-05, 'epoch': 0.67}
{'loss': 0.8817, 'grad_norm': 0.9981318571490256, 'learning_rate': 3.33779443254818e-05, 'epoch': 0.68}
{'loss': 0.8683, 'grad_norm': 0.882852915505365, 'learning_rate': 3.311027837259101e-05, 'epoch': 0.68}
{'loss': 0.8807, 'grad_norm': 1.068383603779803, 'learning_rate': 3.284261241970021e-05, 'epoch': 0.68}
{'loss': 0.8604, 'grad_norm': 1.1208901336586738, 'learning_rate': 3.257494646680942e-05, 'epoch': 0.68}
{'loss': 0.8724, 'grad_norm': 1.0741745699494158, 'learning_rate': 3.230728051391863e-05, 'epoch': 0.69}
{'loss': 0.9015, 'grad_norm': 1.0622407949387869, 'learning_rate': 3.2039614561027836e-05, 'epoch': 0.69}
{'loss': 0.81, 'grad_norm': 0.8404517945942782, 'learning_rate': 3.1771948608137047e-05, 'epoch': 0.69}
{'loss': 0.867, 'grad_norm': 1.0732079308057685, 'learning_rate': 3.1504282655246257e-05, 'epoch': 0.69}
{'loss': 0.8331, 'grad_norm': 1.1816672991173003, 'learning_rate': 3.1236616702355467e-05, 'epoch': 0.7}
{'loss': 0.8404, 'grad_norm': 1.038837299790726, 'learning_rate': 3.096895074946467e-05, 'epoch': 0.7}
{'loss': 0.8912, 'grad_norm': 1.1942844569757316, 'learning_rate': 3.070128479657387e-05, 'epoch': 0.7}
{'loss': 0.8798, 'grad_norm': 1.0860917030313382, 'learning_rate': 3.0433618843683086e-05, 'epoch': 0.7}
{'loss': 0.8397, 'grad_norm': 0.9919120909410555, 'learning_rate': 3.0165952890792293e-05, 'epoch': 0.71}
{'loss': 0.8159, 'grad_norm': 0.948387973180485, 'learning_rate': 2.98982869379015e-05, 'epoch': 0.71}
{'loss': 0.8664, 'grad_norm': 0.9173429456411075, 'learning_rate': 2.963062098501071e-05, 'epoch': 0.71}
{'loss': 0.8541, 'grad_norm': 1.0456865060447273, 'learning_rate': 2.9362955032119916e-05, 'epoch': 0.71}
{'loss': 0.9009, 'grad_norm': 1.0625190814931085, 'learning_rate': 2.909528907922912e-05, 'epoch': 0.72}
{'loss': 0.8213, 'grad_norm': 1.0924728903230494, 'learning_rate': 2.8827623126338333e-05, 'epoch': 0.72}
{'loss': 0.8577, 'grad_norm': 1.1056730256421583, 'learning_rate': 2.8559957173447536e-05, 'epoch': 0.72}
{'loss': 0.8032, 'grad_norm': 0.8706039821875462, 'learning_rate': 2.829229122055675e-05, 'epoch': 0.72}
{'loss': 0.8783, 'grad_norm': 1.0681867831742484, 'learning_rate': 2.8024625267665956e-05, 'epoch': 0.73}
{'loss': 0.8343, 'grad_norm': 0.8504378170084179, 'learning_rate': 2.775695931477516e-05, 'epoch': 0.73}
{'loss': 0.8741, 'grad_norm': 1.0698562648149057, 'learning_rate': 2.7489293361884373e-05, 'epoch': 0.73}
{'loss': 0.8453, 'grad_norm': 1.114352232185882, 'learning_rate': 2.7221627408993576e-05, 'epoch': 0.74}
{'loss': 0.864, 'grad_norm': 1.2124653942069747, 'learning_rate': 2.6953961456102783e-05, 'epoch': 0.74}
{'loss': 0.8713, 'grad_norm': 1.0928808704028157, 'learning_rate': 2.6686295503211993e-05, 'epoch': 0.74}
{'loss': 0.8334, 'grad_norm': 0.9699298179020516, 'learning_rate': 2.64186295503212e-05, 'epoch': 0.74}
{'loss': 0.8672, 'grad_norm': 1.167399860555264, 'learning_rate': 2.6150963597430406e-05, 'epoch': 0.75}
{'loss': 0.877, 'grad_norm': 1.1112584830496557, 'learning_rate': 2.5883297644539616e-05, 'epoch': 0.75}
{'loss': 0.8142, 'grad_norm': 1.0997741962131276, 'learning_rate': 2.5615631691648823e-05, 'epoch': 0.75}
{'loss': 0.8529, 'grad_norm': 0.9797486318369024, 'learning_rate': 2.5347965738758033e-05, 'epoch': 0.75}
{'loss': 0.8792, 'grad_norm': 1.0232182877315672, 'learning_rate': 2.508029978586724e-05, 'epoch': 0.76}
{'loss': 0.8613, 'grad_norm': 0.9634376173905049, 'learning_rate': 2.481263383297645e-05, 'epoch': 0.76}
{'loss': 0.8358, 'grad_norm': 1.0119748058515226, 'learning_rate': 2.4544967880085653e-05, 'epoch': 0.76}
{'loss': 0.7844, 'grad_norm': 1.1262562086656072, 'learning_rate': 2.4277301927194863e-05, 'epoch': 0.76}
{'loss': 0.828, 'grad_norm': 1.1348790976481433, 'learning_rate': 2.400963597430407e-05, 'epoch': 0.77}
{'loss': 0.8857, 'grad_norm': 0.9620734229186473, 'learning_rate': 2.3741970021413276e-05, 'epoch': 0.77}
{'loss': 0.8689, 'grad_norm': 1.0421820142180778, 'learning_rate': 2.3474304068522486e-05, 'epoch': 0.77}
{'loss': 0.7886, 'grad_norm': 1.0122901271590343, 'learning_rate': 2.3206638115631693e-05, 'epoch': 0.77}
{'loss': 0.8692, 'grad_norm': 1.0532963025498652, 'learning_rate': 2.2938972162740903e-05, 'epoch': 0.78}
{'loss': 0.8257, 'grad_norm': 1.006997766987204, 'learning_rate': 2.2671306209850106e-05, 'epoch': 0.78}
{'loss': 0.8523, 'grad_norm': 0.9960217095501381, 'learning_rate': 2.2403640256959316e-05, 'epoch': 0.78}
{'loss': 0.8011, 'grad_norm': 1.0445358211323368, 'learning_rate': 2.2135974304068523e-05, 'epoch': 0.78}
{'loss': 0.81, 'grad_norm': 0.9320280932710217, 'learning_rate': 2.1868308351177733e-05, 'epoch': 0.79}
{'loss': 0.8763, 'grad_norm': 1.0828136733858365, 'learning_rate': 2.160064239828694e-05, 'epoch': 0.79}
{'loss': 0.8934, 'grad_norm': 1.015453081355755, 'learning_rate': 2.1332976445396146e-05, 'epoch': 0.79}
{'loss': 0.7953, 'grad_norm': 0.9933475836765012, 'learning_rate': 2.1065310492505356e-05, 'epoch': 0.8}
{'loss': 0.8365, 'grad_norm': 0.9320409373505445, 'learning_rate': 2.079764453961456e-05, 'epoch': 0.8}
{'loss': 0.816, 'grad_norm': 0.991295005094353, 'learning_rate': 2.052997858672377e-05, 'epoch': 0.8}
{'loss': 0.7946, 'grad_norm': 1.1885488601098406, 'learning_rate': 2.026231263383298e-05, 'epoch': 0.8}
{'loss': 0.865, 'grad_norm': 1.1314263619307943, 'learning_rate': 1.9994646680942186e-05, 'epoch': 0.81}
{'loss': 0.8239, 'grad_norm': 1.0379507117611184, 'learning_rate': 1.9726980728051393e-05, 'epoch': 0.81}
{'loss': 0.8693, 'grad_norm': 1.1587522635624385, 'learning_rate': 1.94593147751606e-05, 'epoch': 0.81}
{'loss': 0.8609, 'grad_norm': 1.2337515501952727, 'learning_rate': 1.919164882226981e-05, 'epoch': 0.81}
{'loss': 0.8941, 'grad_norm': 1.095991633049057, 'learning_rate': 1.8923982869379016e-05, 'epoch': 0.82}
{'loss': 0.8764, 'grad_norm': 1.2429517784899105, 'learning_rate': 1.8656316916488223e-05, 'epoch': 0.82}
{'loss': 0.847, 'grad_norm': 0.9319008562536849, 'learning_rate': 1.8388650963597433e-05, 'epoch': 0.82}
{'loss': 0.8575, 'grad_norm': 1.0497062258448748, 'learning_rate': 1.812098501070664e-05, 'epoch': 0.82}
{'loss': 0.8917, 'grad_norm': 1.1202664381737262, 'learning_rate': 1.7853319057815846e-05, 'epoch': 0.83}
{'loss': 0.8117, 'grad_norm': 1.069014238569319, 'learning_rate': 1.7585653104925052e-05, 'epoch': 0.83}
{'loss': 0.7842, 'grad_norm': 1.0899452081791603, 'learning_rate': 1.7317987152034263e-05, 'epoch': 0.83}
{'loss': 0.8844, 'grad_norm': 1.2807617021403455, 'learning_rate': 1.705032119914347e-05, 'epoch': 0.83}
{'loss': 0.836, 'grad_norm': 1.0772132542062212, 'learning_rate': 1.6782655246252676e-05, 'epoch': 0.84}
{'loss': 0.8015, 'grad_norm': 1.0719513002832735, 'learning_rate': 1.6514989293361886e-05, 'epoch': 0.84}
{'loss': 0.8386, 'grad_norm': 0.9761661661382187, 'learning_rate': 1.6247323340471092e-05, 'epoch': 0.84}
{'loss': 0.7977, 'grad_norm': 0.9977931367881281, 'learning_rate': 1.5979657387580302e-05, 'epoch': 0.84}
{'loss': 0.8314, 'grad_norm': 1.064092981201798, 'learning_rate': 1.571199143468951e-05, 'epoch': 0.85}
{'loss': 0.8686, 'grad_norm': 1.0934954829627042, 'learning_rate': 1.5444325481798716e-05, 'epoch': 0.85}
{'loss': 0.8677, 'grad_norm': 1.0801365014934918, 'learning_rate': 1.5176659528907924e-05, 'epoch': 0.85}
{'loss': 0.8792, 'grad_norm': 1.0098963960140879, 'learning_rate': 1.490899357601713e-05, 'epoch': 0.86}
{'loss': 0.8775, 'grad_norm': 1.1406673269781757, 'learning_rate': 1.4641327623126339e-05, 'epoch': 0.86}
{'loss': 0.8312, 'grad_norm': 1.1514383927231677, 'learning_rate': 1.4373661670235547e-05, 'epoch': 0.86}
{'loss': 0.8177, 'grad_norm': 0.9434021151642957, 'learning_rate': 1.4105995717344756e-05, 'epoch': 0.86}
{'loss': 0.8054, 'grad_norm': 0.9771281237582765, 'learning_rate': 1.383832976445396e-05, 'epoch': 0.87}
{'loss': 0.8457, 'grad_norm': 1.0801120761506249, 'learning_rate': 1.3570663811563169e-05, 'epoch': 0.87}
{'loss': 0.8328, 'grad_norm': 1.0017949624246827, 'learning_rate': 1.3302997858672377e-05, 'epoch': 0.87}
{'loss': 0.916, 'grad_norm': 1.0859290470995973, 'learning_rate': 1.3035331905781586e-05, 'epoch': 0.87}
{'loss': 0.8352, 'grad_norm': 0.9732491607275341, 'learning_rate': 1.2767665952890792e-05, 'epoch': 0.88}
{'loss': 0.8736, 'grad_norm': 1.1114933958487692, 'learning_rate': 1.25e-05, 'epoch': 0.88}
{'loss': 0.8647, 'grad_norm': 0.9661360601430125, 'learning_rate': 1.2232334047109207e-05, 'epoch': 0.88}
{'loss': 0.8659, 'grad_norm': 1.0341117597636216, 'learning_rate': 1.1964668094218416e-05, 'epoch': 0.88}
{'loss': 0.8071, 'grad_norm': 1.1492798585673043, 'learning_rate': 1.1697002141327624e-05, 'epoch': 0.89}
{'loss': 0.8167, 'grad_norm': 1.0453997995929194, 'learning_rate': 1.1429336188436832e-05, 'epoch': 0.89}
{'loss': 0.812, 'grad_norm': 0.9894801679056846, 'learning_rate': 1.1161670235546039e-05, 'epoch': 0.89}
{'loss': 0.8259, 'grad_norm': 1.2514649057123557, 'learning_rate': 1.0894004282655247e-05, 'epoch': 0.89}
{'loss': 0.8311, 'grad_norm': 1.1878326201162523, 'learning_rate': 1.0626338329764454e-05, 'epoch': 0.9}
{'loss': 0.8293, 'grad_norm': 1.2845412715830935, 'learning_rate': 1.0358672376873662e-05, 'epoch': 0.9}
{'loss': 0.9118, 'grad_norm': 1.0721293340132443, 'learning_rate': 1.009100642398287e-05, 'epoch': 0.9}
{'loss': 0.8377, 'grad_norm': 1.104325454748754, 'learning_rate': 9.823340471092079e-06, 'epoch': 0.9}
{'loss': 0.8812, 'grad_norm': 1.0578297694061618, 'learning_rate': 9.555674518201285e-06, 'epoch': 0.91}
{'loss': 0.9056, 'grad_norm': 0.9680884354715635, 'learning_rate': 9.288008565310492e-06, 'epoch': 0.91}
{'loss': 0.8475, 'grad_norm': 0.9988918400628429, 'learning_rate': 9.0203426124197e-06, 'epoch': 0.91}
{'loss': 0.8352, 'grad_norm': 1.1587253218547418, 'learning_rate': 8.752676659528907e-06, 'epoch': 0.92}
{'loss': 0.8583, 'grad_norm': 1.129684603676885, 'learning_rate': 8.485010706638117e-06, 'epoch': 0.92}
{'loss': 0.7547, 'grad_norm': 0.8975647691263297, 'learning_rate': 8.217344753747324e-06, 'epoch': 0.92}
{'loss': 0.8152, 'grad_norm': 1.02370665323384, 'learning_rate': 7.949678800856532e-06, 'epoch': 0.92}
{'loss': 0.8005, 'grad_norm': 1.0041044459752242, 'learning_rate': 7.682012847965739e-06, 'epoch': 0.93}
{'loss': 0.8018, 'grad_norm': 1.0763460616982505, 'learning_rate': 7.414346895074947e-06, 'epoch': 0.93}
{'loss': 0.8676, 'grad_norm': 1.1453879483105631, 'learning_rate': 7.1466809421841545e-06, 'epoch': 0.93}
{'loss': 0.8302, 'grad_norm': 0.9863318875238625, 'learning_rate': 6.879014989293363e-06, 'epoch': 0.93}
{'loss': 0.7448, 'grad_norm': 0.8546920102902061, 'learning_rate': 6.6113490364025695e-06, 'epoch': 0.94}
{'loss': 0.8938, 'grad_norm': 1.0493638055366152, 'learning_rate': 6.343683083511777e-06, 'epoch': 0.94}
{'loss': 0.8348, 'grad_norm': 1.10237730091245, 'learning_rate': 6.076017130620985e-06, 'epoch': 0.94}
{'loss': 0.8119, 'grad_norm': 1.1887723142318432, 'learning_rate': 5.808351177730193e-06, 'epoch': 0.94}
{'loss': 0.8405, 'grad_norm': 1.0604892699015602, 'learning_rate': 5.540685224839401e-06, 'epoch': 0.95}
{'loss': 0.8929, 'grad_norm': 1.0448581691024972, 'learning_rate': 5.273019271948609e-06, 'epoch': 0.95}
{'loss': 0.8529, 'grad_norm': 1.19136143229594, 'learning_rate': 5.005353319057816e-06, 'epoch': 0.95}
{'loss': 0.7936, 'grad_norm': 1.1392020240032663, 'learning_rate': 4.7376873661670236e-06, 'epoch': 0.95}
{'loss': 0.8597, 'grad_norm': 1.0303600301904692, 'learning_rate': 4.470021413276231e-06, 'epoch': 0.96}
{'loss': 0.8875, 'grad_norm': 1.1006762016429712, 'learning_rate': 4.202355460385439e-06, 'epoch': 0.96}
{'loss': 0.8603, 'grad_norm': 1.1816995823915981, 'learning_rate': 3.934689507494647e-06, 'epoch': 0.96}
{'loss': 0.8161, 'grad_norm': 1.0903749865941457, 'learning_rate': 3.6670235546038543e-06, 'epoch': 0.96}
{'loss': 0.8757, 'grad_norm': 1.0559569407847411, 'learning_rate': 3.3993576017130622e-06, 'epoch': 0.97}
{'loss': 0.8322, 'grad_norm': 1.087050041983202, 'learning_rate': 3.13169164882227e-06, 'epoch': 0.97}
{'loss': 0.8622, 'grad_norm': 1.3019240931015608, 'learning_rate': 2.8640256959314776e-06, 'epoch': 0.97}
{'loss': 0.7824, 'grad_norm': 0.8965926336147361, 'learning_rate': 2.5963597430406855e-06, 'epoch': 0.97}
{'loss': 0.8739, 'grad_norm': 1.087623133675985, 'learning_rate': 2.328693790149893e-06, 'epoch': 0.98}
{'loss': 0.7904, 'grad_norm': 0.9837833560702006, 'learning_rate': 2.0610278372591005e-06, 'epoch': 0.98}
{'loss': 0.8546, 'grad_norm': 1.1051881551449354, 'learning_rate': 1.7933618843683084e-06, 'epoch': 0.98}
{'loss': 0.8589, 'grad_norm': 1.0413985528316654, 'learning_rate': 1.5256959314775161e-06, 'epoch': 0.99}
{'loss': 0.8513, 'grad_norm': 1.052712663779879, 'learning_rate': 1.2580299785867238e-06, 'epoch': 0.99}
{'loss': 0.8181, 'grad_norm': 1.1950856200732074, 'learning_rate': 9.903640256959315e-07, 'epoch': 0.99}
{'loss': 0.7865, 'grad_norm': 0.96495349129843, 'learning_rate': 7.226980728051392e-07, 'epoch': 0.99}
{'loss': 0.8172, 'grad_norm': 1.1631589868011272, 'learning_rate': 4.550321199143469e-07, 'epoch': 1.0}
{'loss': 0.8168, 'grad_norm': 1.0143757523986383, 'learning_rate': 1.8736616702355462e-07, 'epoch': 1.0}
{'train_runtime': 67563.4117, 'train_samples_per_second': 7.267, 'train_steps_per_second': 0.057, 'train_loss': 0.9142391137211614, 'epoch': 1.0}
[2025-05-06 15:59:19,224] [INFO] [launch.py:351:main] Process 22433 exits successfully.
[2025-05-06 15:59:19,225] [INFO] [launch.py:351:main] Process 22432 exits successfully.
[2025-05-06 15:59:19,226] [INFO] [launch.py:351:main] Process 22435 exits successfully.
[2025-05-06 15:59:19,226] [INFO] [launch.py:351:main] Process 22429 exits successfully.
[2025-05-06 15:59:19,227] [INFO] [launch.py:351:main] Process 22430 exits successfully.
[2025-05-06 15:59:19,227] [INFO] [launch.py:351:main] Process 22434 exits successfully.
[2025-05-06 15:59:19,228] [INFO] [launch.py:351:main] Process 22431 exits successfully.
[2025-05-06 15:59:20,229] [INFO] [launch.py:351:main] Process 22428 exits successfully.
====== encode query
[2025-05-06 16:00:14,162] [INFO] [real_accelerator.py:239:get_accelerator] Setting ds_accelerator to cuda (auto detect)
====== encode corpus
[2025-05-06 16:01:38,113] [INFO] [real_accelerator.py:239:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2025-05-06 16:01:38,195] [INFO] [real_accelerator.py:239:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2025-05-06 16:01:38,468] [INFO] [real_accelerator.py:239:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2025-05-06 16:01:38,484] [INFO] [real_accelerator.py:239:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2025-05-06 16:01:38,700] [INFO] [real_accelerator.py:239:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2025-05-06 16:01:38,705] [INFO] [real_accelerator.py:239:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2025-05-06 16:01:38,712] [INFO] [real_accelerator.py:239:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2025-05-06 16:01:38,881] [INFO] [real_accelerator.py:239:get_accelerator] Setting ds_accelerator to cuda (auto detect)
====== Search the Corpus
====== Evaluation
recall_5              	all	0.6012
recall_10             	all	0.7215
recall_15             	all	0.7794
recall_20             	all	0.8185
recall_30             	all	0.8628
recall_100            	all	0.9436
recall_200            	all	0.9687
recall_500            	all	0.9876
recall_1000           	all	0.9945
recall_50             	all	0.9023
recall_1000           	all	0.9945
recip_rank            	all	0.4282
ndcg_cut_10           	all	0.4882
ndcg_cut_20           	all	0.5132
{'NDCG@1': 0.27779, 'NDCG@5': 0.44849, 'NDCG@10': 0.48817, 'NDCG@50': 0.53039, 'NDCG@100': 0.53731, 'NDCG@1000': 0.54409, 'MAP@1': 0.26988, 'MAP@5': 0.3951, 'MAP@10': 0.41196, 'MAP@50': 0.42204, 'MAP@100': 0.4227, 'MAP@1000': 0.42298, 'Recall@1': 0.26988, 'Recall@5': 0.60124, 'Recall@10': 0.72151, 'Recall@50': 0.90229, 'Recall@100': 0.94355, 'Recall@1000': 0.9945, 'MRR@1': 0.27779, 'MRR@5': 0.40191, 'MRR@10': 0.41806, 'MRR@50': 0.42743, 'MRR@100': 0.428, 'MRR@1000': 0.42824}
====== encode query
[2025-05-06 20:11:02,250] [INFO] [real_accelerator.py:239:get_accelerator] Setting ds_accelerator to cuda (auto detect)
====== Search the Corpus
====== Evaluation
recall_5              	all	0.1060
recall_10             	all	0.1753
recall_15             	all	0.2375
recall_20             	all	0.2879
recall_30             	all	0.3625
recall_100            	all	0.5658
recall_200            	all	0.6747
recall_500            	all	0.7865
recall_1000           	all	0.8429
recall_50             	all	0.4587
recall_1000           	all	0.8429
recip_rank            	all	0.9612
ndcg_cut_10           	all	0.7333
ndcg_cut_20           	all	0.7264
====== encode query
[2025-05-06 20:32:29,015] [INFO] [real_accelerator.py:239:get_accelerator] Setting ds_accelerator to cuda (auto detect)
====== Search the Corpus
====== Evaluation
recall_5              	all	0.1561
recall_10             	all	0.2482
recall_15             	all	0.3111
recall_20             	all	0.3589
recall_30             	all	0.4196
recall_100            	all	0.6083
recall_200            	all	0.6796
recall_500            	all	0.7383
recall_1000           	all	0.7846
recall_50             	all	0.5108
recall_1000           	all	0.7846
recip_rank            	all	0.9334
ndcg_cut_10           	all	0.7341
ndcg_cut_20           	all	0.7027
